{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "172aaebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\hp\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "238a87ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rouge in c:\\users\\hp\\anaconda3\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: six in c:\\users\\hp\\anaconda3\\lib\\site-packages (from rouge) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install rouge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51eab351",
   "metadata": {},
   "source": [
    "# Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afe40f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from nltk.cluster.util import cosine_distance\n",
    "from operator import itemgetter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from rouge import Rouge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e9b5c9",
   "metadata": {},
   "source": [
    "# Download NLTK resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22cf9a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9815a93",
   "metadata": {},
   "source": [
    "# Sample paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53d9fc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = \"\"\"\n",
    "Natural language processing (NLP) is a field of artificial intelligence that focuses on the interaction between computers and humans using natural language. It enables computers to understand, interpret, and generate human-like text. NLP involves several challenges, including natural language understanding, language generation, and language translation. Text summarization is a specific NLP task that involves reducing the length of a document while retaining its key information. There are two main approaches to text summarization: extractive and abstractive. Extractive methods select important sentences from the original text, while abstractive methods generate new sentences to form the summary.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c719b9ef",
   "metadata": {},
   "source": [
    "# Function to perform sentence tokenization and remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "439152ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    preprocessed_sentences = [word_tokenize(sentence.lower()) for sentence in sentences]\n",
    "    preprocessed_sentences = [[word for word in sentence if word.isalnum() and word not in stop_words] for sentence in preprocessed_sentences]\n",
    "    return preprocessed_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab87584",
   "metadata": {},
   "source": [
    "# Function to calculate sentence similarity using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bafd1179",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity(sentences):\n",
    "    detokenizer = TreebankWordDetokenizer()\n",
    "    detokenized_sentences = [detokenizer.detokenize(sentence) for sentence in sentences]\n",
    "    \n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(detokenized_sentences)\n",
    "    \n",
    "    similarity_matrix = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "    return similarity_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b34439",
   "metadata": {},
   "source": [
    "# Function to perform TextRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8701e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_rank(sentences, similarity_matrix, d=0.85, max_iter=50, tol=0.001):\n",
    "    scores = [1.0] * len(sentences)\n",
    "    for _ in range(max_iter):\n",
    "        prev_scores = scores.copy()\n",
    "        for i in range(len(sentences)):\n",
    "            summation = 0\n",
    "            for j in range(len(sentences)):\n",
    "                if i != j:\n",
    "                    summation += similarity_matrix[j][i] * scores[j] / sum(similarity_matrix[j])\n",
    "            scores[i] = (1 - d) + d * summation\n",
    "\n",
    "        if sum(abs(scores[i] - prev_scores[i]) for i in range(len(scores))) < tol:\n",
    "            break\n",
    "\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f045ab",
   "metadata": {},
   "source": [
    "# Function to perform TextRank summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab36a6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_rank_summarization(text, num_sentences=3):\n",
    "    sentences = preprocess_text(text)\n",
    "    similarity_matrix = calculate_similarity(sentences)\n",
    "    scores = text_rank(sentences, similarity_matrix)\n",
    "\n",
    "    ranked_sentences = [(sentences[i], scores[i]) for i in range(len(sentences))]\n",
    "    ranked_sentences = sorted(ranked_sentences, key=itemgetter(1), reverse=True)[:num_sentences]\n",
    "\n",
    "    summary = [sentence[0] for sentence in ranked_sentences]\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa84c57",
   "metadata": {},
   "source": [
    "# Function to calculate Overlap Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a479582",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap_ratio(reference, generated):\n",
    "    reference_set = set(reference.split())\n",
    "    generated_set = set(generated.split())\n",
    "    \n",
    "    overlap_count = len(reference_set.intersection(generated_set))\n",
    "    total_count = len(reference_set) + len(generated_set)\n",
    "    \n",
    "    return overlap_count / (total_count / 2)  # Normalize by the average length\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb71fd5",
   "metadata": {},
   "source": [
    "# Function to calculate ROUGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c12ddca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rouge(reference, generated):\n",
    "    rouge = Rouge()\n",
    "    scores = rouge.get_scores(generated, reference)\n",
    "    return scores[0]['rouge-1']['f']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a9d875",
   "metadata": {},
   "source": [
    "# Given reference summary (ground truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f6395ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_summary = \"Natural language processing (NLP) is a field of artificial intelligence that focuses on the interaction between computers and humans using natural language.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab59b372",
   "metadata": {},
   "source": [
    "# Perform TextRank summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c13cb570",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_summary = text_rank_summarization(paragraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88477bfd",
   "metadata": {},
   "source": [
    "# Print the generated summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a80543b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Summary:\n",
      "natural language processing nlp field artificial intelligence focuses interaction computers humans using natural language\n",
      "nlp involves several challenges including natural language understanding language generation language translation\n",
      "two main approaches text summarization extractive abstractive\n"
     ]
    }
   ],
   "source": [
    "print(\"Generated Summary:\")\n",
    "print(\"\\n\".join(\" \".join(sentence) for sentence in generated_summary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efffd75b",
   "metadata": {},
   "source": [
    "# Calculate and print the performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13678b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overlap Ratio: 0.4583333333333333\n",
      "ROUGE Score: 0.4680851014395655\n"
     ]
    }
   ],
   "source": [
    "overlap_ratio_score = overlap_ratio(reference_summary, \" \".join(\" \".join(sentence) for sentence in generated_summary))\n",
    "rouge_score = calculate_rouge(reference_summary, \" \".join(\" \".join(sentence) for sentence in generated_summary))\n",
    "\n",
    "print(\"\\nOverlap Ratio:\", overlap_ratio_score)\n",
    "print(\"ROUGE Score:\", rouge_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a8babf",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
